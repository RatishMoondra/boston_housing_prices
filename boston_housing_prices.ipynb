{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#format the floating points in Jupyter output cell\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "# Set the float format using np.set_printoptions()\n",
    "np.set_printoptions(precision=2, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import boston housing price dataset from keras\n",
    "\n",
    "from tensorflow.keras.datasets import boston_housing\n",
    "(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data : (404, 13)\n",
      "Test Data : (102, 13)\n",
      "Training Samples : [  0.02  82.5    2.03   0.     0.41   7.61  15.7    6.27   2.   348.\n",
      "  14.7  395.38   3.11]\n",
      "Training Target Samples : 42.3\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data : {train_data.shape}\")\n",
    "print(f\"Test Data : {test_data.shape}\")\n",
    "print(f\"Training Samples : {train_data[1]}\")\n",
    "print(f\"Training Target Samples : {train_targets[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3.75,  11.48,  11.1 ,   0.06,   0.56,   6.27,  69.01,   3.74,\n",
       "         9.44, 405.9 ,  18.48, 354.78,  12.74])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import StandardScaler and Scale the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaled_train_data = scaler.fit_transform(train_data)\n",
    "scaled_test_data = scaler.transform(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                896       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,121\n",
      "Trainable params: 5,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#building the neural network\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "model = Sequential([\n",
    "    Dense(64,activation='relu' ,input_shape=(scaled_train_data.shape[1],)),\n",
    "    Dense(64,activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "#compile the model using adam optimizer \n",
    "model.compile(optimizer='rmsprop',loss='mse', metrics=['mae'])  \n",
    "model.summary()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the required module for visualization\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "# Generate the image file for the model summary\n",
    "plot_model(model, to_file='model_summary.png', show_shapes=True, show_layer_names=True, rankdir='LR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fold 0\n",
      "Processing fold 1\n",
      "Processing fold 2\n",
      "Processing fold 3\n"
     ]
    }
   ],
   "source": [
    "# K-fold validation\n",
    "k = 4 \n",
    "num_val_samples = len(scaled_train_data) // k\n",
    "num_epochs = 100\n",
    "all_scores = []\n",
    "\n",
    "for i in range(k):\n",
    "    print(f\"Processing fold {i}\")\n",
    "    val_data = scaled_train_data[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    partial_train_data = np.concatenate( \n",
    "        [scaled_train_data[:i * num_val_samples],\n",
    "          scaled_train_data[(i + 1) * num_val_samples:]],\n",
    "          axis=0)\n",
    "    partial_train_targets = np.concatenate(\n",
    "        [train_targets[:i * num_val_samples],\n",
    "          train_targets[(i + 1) * num_val_samples:]],\n",
    "          axis=0)\n",
    "    model.fit(partial_train_data, partial_train_targets,epochs=num_epochs,batch_size=1,verbose=0)\n",
    "    val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
    "    all_scores.append(val_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_scores : [2.1902554035186768, 2.423675775527954, 1.9264979362487793, 1.5690051317214966]\n",
      "mean_scores : 2.0273585617542267\n",
      "std_scores : 0.31775125790086245\n"
     ]
    }
   ],
   "source": [
    "print(f\"all_scores : {all_scores}\")\n",
    "print(f\"mean_scores : {np.mean(all_scores)}\")\n",
    "print(f\"std_scores : {np.std(all_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.XTick at 0x1e419072d10>,\n",
       "  <matplotlib.axis.XTick at 0x1e418f34bd0>,\n",
       "  <matplotlib.axis.XTick at 0x1e4190f6890>,\n",
       "  <matplotlib.axis.XTick at 0x1e41b8531d0>],\n",
       " [Text(0, 0, '0'), Text(1, 0, '1'), Text(2, 0, '2'), Text(3, 0, '3')])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Draw a line plot for all_scores variable\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(all_scores)\n",
    "plt.xticks(range(k))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 1.7859 - mae: 0.8398\n",
      "Epoch 2/80\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 1.4930 - mae: 0.8135\n",
      "Epoch 3/80\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 1.2571 - mae: 0.7579\n",
      "Epoch 4/80\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 1.1817 - mae: 0.7787\n",
      "Epoch 5/80\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 1.0878 - mae: 0.7307\n",
      "Epoch 6/80\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 1.0000 - mae: 0.7104\n",
      "Epoch 7/80\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.9518 - mae: 0.6892\n",
      "Epoch 8/80\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.9746 - mae: 0.7101\n",
      "Epoch 9/80\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.9007 - mae: 0.6819\n",
      "Epoch 10/80\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.9180 - mae: 0.6698\n",
      "Epoch 11/80\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.8931 - mae: 0.6653\n",
      "Epoch 12/80\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.8817 - mae: 0.6498\n",
      "Epoch 13/80\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.8294 - mae: 0.6310\n",
      "Epoch 14/80\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.8302 - mae: 0.6422\n",
      "Epoch 15/80\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.8308 - mae: 0.6318\n",
      "Epoch 16/80\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.7993 - mae: 0.6520\n",
      "Epoch 17/80\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.7342 - mae: 0.5993\n",
      "Epoch 18/80\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.8479 - mae: 0.6367\n",
      "Epoch 19/80\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.7266 - mae: 0.6051\n",
      "Epoch 20/80\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.7591 - mae: 0.6323\n",
      "Epoch 21/80\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.7316 - mae: 0.6218\n",
      "Epoch 22/80\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.7562 - mae: 0.6094\n",
      "Epoch 23/80\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.7063 - mae: 0.5740\n",
      "Epoch 24/80\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.7183 - mae: 0.6002\n",
      "Epoch 25/80\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.7658 - mae: 0.6171\n",
      "Epoch 26/80\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.7231 - mae: 0.6016\n",
      "Epoch 27/80\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.7530 - mae: 0.6032\n",
      "Epoch 28/80\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.6611 - mae: 0.5903\n",
      "Epoch 29/80\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.7185 - mae: 0.5839\n",
      "Epoch 30/80\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.6423 - mae: 0.5827\n",
      "Epoch 31/80\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.6575 - mae: 0.5765\n",
      "Epoch 32/80\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.7143 - mae: 0.5974\n",
      "Epoch 33/80\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5985 - mae: 0.5596\n",
      "Epoch 34/80\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6955 - mae: 0.5930\n",
      "Epoch 35/80\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6304 - mae: 0.5662\n",
      "Epoch 36/80\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5780 - mae: 0.5535\n",
      "Epoch 37/80\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6677 - mae: 0.5768\n",
      "Epoch 38/80\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6358 - mae: 0.5605\n",
      "Epoch 39/80\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.6526 - mae: 0.5690\n",
      "Epoch 40/80\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.6226 - mae: 0.5663\n",
      "Epoch 41/80\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5654 - mae: 0.5342\n",
      "Epoch 42/80\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.6137 - mae: 0.5464\n",
      "Epoch 43/80\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6164 - mae: 0.5735\n",
      "Epoch 44/80\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.6392 - mae: 0.5823\n",
      "Epoch 45/80\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5519 - mae: 0.5204\n",
      "Epoch 46/80\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.6152 - mae: 0.5562\n",
      "Epoch 47/80\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5619 - mae: 0.5337\n",
      "Epoch 48/80\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5818 - mae: 0.5602\n",
      "Epoch 49/80\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6353 - mae: 0.5451\n",
      "Epoch 50/80\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5973 - mae: 0.5576\n",
      "Epoch 51/80\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5927 - mae: 0.5244\n",
      "Epoch 52/80\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5899 - mae: 0.5289\n",
      "Epoch 53/80\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5626 - mae: 0.5315\n",
      "Epoch 54/80\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.6137 - mae: 0.5157\n",
      "Epoch 55/80\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5575 - mae: 0.5346\n",
      "Epoch 56/80\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5783 - mae: 0.5457\n",
      "Epoch 57/80\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5620 - mae: 0.5205\n",
      "Epoch 58/80\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5106 - mae: 0.5158\n",
      "Epoch 59/80\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5990 - mae: 0.5501\n",
      "Epoch 60/80\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5619 - mae: 0.5157\n",
      "Epoch 61/80\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5633 - mae: 0.5308\n",
      "Epoch 62/80\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4995 - mae: 0.4881\n",
      "Epoch 63/80\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5473 - mae: 0.5249\n",
      "Epoch 64/80\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5616 - mae: 0.5259\n",
      "Epoch 65/80\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5631 - mae: 0.5379\n",
      "Epoch 66/80\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5319 - mae: 0.5049\n",
      "Epoch 67/80\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4829 - mae: 0.5070\n",
      "Epoch 68/80\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4893 - mae: 0.5077\n",
      "Epoch 69/80\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5557 - mae: 0.5308\n",
      "Epoch 70/80\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5154 - mae: 0.5017\n",
      "Epoch 71/80\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5875 - mae: 0.5318\n",
      "Epoch 72/80\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4305 - mae: 0.4617\n",
      "Epoch 73/80\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5232 - mae: 0.5085\n",
      "Epoch 74/80\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5183 - mae: 0.5072\n",
      "Epoch 75/80\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4579 - mae: 0.4790\n",
      "Epoch 76/80\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4715 - mae: 0.4902\n",
      "Epoch 77/80\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5340 - mae: 0.5015\n",
      "Epoch 78/80\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4810 - mae: 0.4828\n",
      "Epoch 79/80\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5709 - mae: 0.5312\n",
      "Epoch 80/80\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4683 - mae: 0.4918\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 12.2602 - mae: 2.5215\n"
     ]
    }
   ],
   "source": [
    "model.fit(scaled_train_data, train_targets, epochs=80, batch_size=16)\n",
    "test_mse_score, test_mea_score  = model.evaluate(scaled_test_data, test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.521510601043701 12.260225296020508\n"
     ]
    }
   ],
   "source": [
    "print(test_mea_score, test_mse_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[  1.23,   0.  ,   8.14, ...,  21.  , 396.9 ,  18.72],\n",
      "       [  0.02,  82.5 ,   2.03, ...,  14.7 , 395.38,   3.11],\n",
      "       [  4.9 ,   0.  ,  18.1 , ...,  20.2 , 375.52,   3.26],\n",
      "       ...,\n",
      "       [  0.03,  35.  ,   6.06, ...,  16.9 , 362.25,   7.83],\n",
      "       [  2.15,   0.  ,  19.58, ...,  14.7 , 261.95,  15.79],\n",
      "       [  0.01,  60.  ,   2.93, ...,  15.6 , 376.7 ,   4.38]]), array([15.2, 42.3, 50. , 21.1, 17.7, 18.5, 11.3, 15.6, 15.6, 14.4, 12.1,\n",
      "       17.9, 23.1, 19.9, 15.7,  8.8, 50. , 22.5, 24.1, 27.5, 10.9, 30.8,\n",
      "       32.9, 24. , 18.5, 13.3, 22.9, 34.7, 16.6, 17.5, 22.3, 16.1, 14.9,\n",
      "       23.1, 34.9, 25. , 13.9, 13.1, 20.4, 20. , 15.2, 24.7, 22.2, 16.7,\n",
      "       12.7, 15.6, 18.4, 21. , 30.1, 15.1, 18.7,  9.6, 31.5, 24.8, 19.1,\n",
      "       22. , 14.5, 11. , 32. , 29.4, 20.3, 24.4, 14.6, 19.5, 14.1, 14.3,\n",
      "       15.6, 10.5,  6.3, 19.3, 19.3, 13.4, 36.4, 17.8, 13.5, 16.5,  8.3,\n",
      "       14.3, 16. , 13.4, 28.6, 43.5, 20.2, 22. , 23. , 20.7, 12.5, 48.5,\n",
      "       14.6, 13.4, 23.7, 50. , 21.7, 39.8, 38.7, 22.2, 34.9, 22.5, 31.1,\n",
      "       28.7, 46. , 41.7, 21. , 26.6, 15. , 24.4, 13.3, 21.2, 11.7, 21.7,\n",
      "       19.4, 50. , 22.8, 19.7, 24.7, 36.2, 14.2, 18.9, 18.3, 20.6, 24.6,\n",
      "       18.2,  8.7, 44. , 10.4, 13.2, 21.2, 37. , 30.7, 22.9, 20. , 19.3,\n",
      "       31.7, 32. , 23.1, 18.8, 10.9, 50. , 19.6,  5. , 14.4, 19.8, 13.8,\n",
      "       19.6, 23.9, 24.5, 25. , 19.9, 17.2, 24.6, 13.5, 26.6, 21.4, 11.9,\n",
      "       22.6, 19.6,  8.5, 23.7, 23.1, 22.4, 20.5, 23.6, 18.4, 35.2, 23.1,\n",
      "       27.9, 20.6, 23.7, 28. , 13.6, 27.1, 23.6, 20.6, 18.2, 21.7, 17.1,\n",
      "        8.4, 25.3, 13.8, 22.2, 18.4, 20.7, 31.6, 30.5, 20.3,  8.8, 19.2,\n",
      "       19.4, 23.1, 23. , 14.8, 48.8, 22.6, 33.4, 21.1, 13.6, 32.2, 13.1,\n",
      "       23.4, 18.9, 23.9, 11.8, 23.3, 22.8, 19.6, 16.7, 13.4, 22.2, 20.4,\n",
      "       21.8, 26.4, 14.9, 24.1, 23.8, 12.3, 29.1, 21. , 19.5, 23.3, 23.8,\n",
      "       17.8, 11.5, 21.7, 19.9, 25. , 33.4, 28.5, 21.4, 24.3, 27.5, 33.1,\n",
      "       16.2, 23.3, 48.3, 22.9, 22.8, 13.1, 12.7, 22.6, 15. , 15.3, 10.5,\n",
      "       24. , 18.5, 21.7, 19.5, 33.2, 23.2,  5. , 19.1, 12.7, 22.3, 10.2,\n",
      "       13.9, 16.3, 17. , 20.1, 29.9, 17.2, 37.3, 45.4, 17.8, 23.2, 29. ,\n",
      "       22. , 18. , 17.4, 34.6, 20.1, 25. , 15.6, 24.8, 28.2, 21.2, 21.4,\n",
      "       23.8, 31. , 26.2, 17.4, 37.9, 17.5, 20. ,  8.3, 23.9,  8.4, 13.8,\n",
      "        7.2, 11.7, 17.1, 21.6, 50. , 16.1, 20.4, 20.6, 21.4, 20.6, 36.5,\n",
      "        8.5, 24.8, 10.8, 21.9, 17.3, 18.9, 36.2, 14.9, 18.2, 33.3, 21.8,\n",
      "       19.7, 31.6, 24.8, 19.4, 22.8,  7.5, 44.8, 16.8, 18.7, 50. , 50. ,\n",
      "       19.5, 20.1, 50. , 17.2, 20.8, 19.3, 41.3, 20.4, 20.5, 13.8, 16.5,\n",
      "       23.9, 20.6, 31.5, 23.3, 16.8, 14. , 33.8, 36.1, 12.8, 18.3, 18.7,\n",
      "       19.1, 29. , 30.1, 50. , 50. , 22. , 11.9, 37.6, 50. , 22.7, 20.8,\n",
      "       23.5, 27.9, 50. , 19.3, 23.9, 22.6, 15.2, 21.7, 19.2, 43.8, 20.3,\n",
      "       33.2, 19.9, 22.5, 32.7, 22. , 17.1, 19. , 15. , 16.1, 25.1, 23.7,\n",
      "       28.7, 37.2, 22.6, 16.4, 25. , 29.8, 22.1, 17.4, 18.1, 30.3, 17.5,\n",
      "       24.7, 12.6, 26.5, 28.7, 13.3, 10.4, 24.4, 23. , 20. , 17.8,  7. ,\n",
      "       11.8, 24.4, 13.8, 19.4, 25.2, 19.4, 19.4, 29.1]))\n",
      "(array([[ 18.08,   0.  ,  18.1 , ...,  20.2 ,  27.25,  29.05],\n",
      "       [  0.12,   0.  ,  10.01, ...,  17.8 , 394.95,  16.21],\n",
      "       [  0.05,   0.  ,   5.19, ...,  20.2 , 396.9 ,   9.74],\n",
      "       ...,\n",
      "       [  1.83,   0.  ,  19.58, ...,  14.7 , 389.61,   1.92],\n",
      "       [  0.36,   0.  ,   6.2 , ...,  17.4 , 391.7 ,   9.71],\n",
      "       [  2.92,   0.  ,  19.58, ...,  14.7 , 240.16,   9.81]]), array([ 7.2, 18.8, 19. , 27. , 22.2, 24.5, 31.2, 22.9, 20.5, 23.2, 18.6,\n",
      "       14.5, 17.8, 50. , 20.8, 24.3, 24.2, 19.8, 19.1, 22.7, 12. , 10.2,\n",
      "       20. , 18.5, 20.9, 23. , 27.5, 30.1,  9.5, 22. , 21.2, 14.1, 33.1,\n",
      "       23.4, 20.1,  7.4, 15.4, 23.8, 20.1, 24.5, 33. , 28.4, 14.1, 46.7,\n",
      "       32.5, 29.6, 28.4, 19.8, 20.2, 25. , 35.4, 20.3,  9.7, 14.5, 34.9,\n",
      "       26.6,  7.2, 50. , 32.4, 21.6, 29.8, 13.1, 27.5, 21.2, 23.1, 21.9,\n",
      "       13. , 23.2,  8.1,  5.6, 21.7, 29.6, 19.6,  7. , 26.4, 18.9, 20.9,\n",
      "       28.1, 35.4, 10.2, 24.3, 43.1, 17.6, 15.4, 16.2, 27.1, 21.4, 21.5,\n",
      "       22.4, 25. , 16.6, 18.6, 22. , 42.8, 35.1, 21.5, 36. , 21.9, 24.1,\n",
      "       50. , 26.7, 25. ]))\n"
     ]
    }
   ],
   "source": [
    "for data in boston_housing.load_data():\n",
    "    print(data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404, 28)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.DataFrame(train_data)\n",
    "df_train['MEDV'] = train_targets\n",
    "df_test = pd.DataFrame(test_data)\n",
    "df_test['MEDV'] = test_targets\n",
    "\n",
    "df = pd.concat([df_train, df_test], axis=1)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the df into X and y\n",
    "X = df.iloc[:, 0:13]\n",
    "y = df.iloc[:, 13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(13, input_dim=13, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7 \n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rachit\\AppData\\Local\\Temp\\ipykernel_20620\\2063509425.py:3: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  es = KerasRegressor( build_fn=baseline_model, epochs=100, batch_size=32, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "# import libraries  KerasRegressor\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "es = KerasRegressor( build_fn=baseline_model, epochs=100, batch_size=32, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 27 calls to <function Model.make_test_function.<locals>.test_function at 0x000001E420E53060> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 29 calls to <function Model.make_test_function.<locals>.test_function at 0x000001E420F99B20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from random import seed\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "estimaters = []\n",
    "estimaters.append((\"StandardScaler\", StandardScaler()))\n",
    "estimaters.append((\"mlp\", es))\n",
    "\n",
    "pipeline = Pipeline(estimaters)\n",
    "kfold = KFold(n_splits=10)\n",
    "results = cross_val_score(pipeline, X, y, cv=kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized : -30.21 (13.79)\n"
     ]
    }
   ],
   "source": [
    "print(\"Standardized : %.2f (%.2f)\" % (np.mean(results), np.std(results)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def larger_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(13, input_shape=(13,), kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(6, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rachit\\AppData\\Local\\Temp\\ipykernel_20620\\568365904.py:9: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  estimaters.append((\"mlp\", KerasRegressor(build_fn=larger_model, epochs=100, batch_size=32, verbose=1)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 1s 1ms/step - loss: 589.1855\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 588.4182\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 587.3492\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 585.7623\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 583.3485\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 579.6468\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 574.3187\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 566.8883\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 556.9693\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 543.9915\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 527.2552\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 507.4484\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 482.4908\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 454.5794\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 421.3240\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 386.1046\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 348.9194\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 310.7594\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 272.2652\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 236.6021\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 203.9525\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 175.9190\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 151.9138\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 133.6715\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 118.5599\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 107.0866\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 97.6041\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 89.3706\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 82.8217\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 76.7446\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 71.6093\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 66.8961\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 62.8004\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 58.6681\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 55.0055\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 51.8713\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 48.8006\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 46.2089\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 43.8404\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 41.6637\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 39.7981\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 38.0915\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 36.5997\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 35.3194\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 34.1330\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 33.1829\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.1918\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 31.4345\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 30.7915\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 30.2119\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 29.6707\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 29.2168\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 28.7716\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 28.3835\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 28.0697\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 27.7046\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 27.4301\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 27.1236\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 26.9039\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 26.6301\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 26.4163\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 26.2129\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 26.0028\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 25.8245\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 25.6484\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 25.4744\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 25.2936\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 25.1440\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 24.9575\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 24.8102\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 24.6646\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 24.5008\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 24.3712\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 24.1778\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 24.0806\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 23.9070\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 23.7799\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 23.6099\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 23.5033\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 23.3452\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 23.1999\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 23.0354\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 22.8815\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 22.7434\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 22.5977\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 22.4623\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 22.3140\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 22.1667\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 22.0244\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 21.8930\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 21.7597\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 21.6328\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 21.5086\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 21.3781\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 21.2658\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 21.1342\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 21.0091\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 20.9146\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 20.7704\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 20.6590\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 35.9670\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 1s 1ms/step - loss: 603.4894\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 602.7394\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 601.8288\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 600.5731\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 598.6195\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 595.6531\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 591.0644\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 584.5932\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 575.3835\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 563.1197\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 546.9900\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 526.7933\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 503.1023\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 475.2364\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 444.0369\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 408.6086\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 372.5347\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 334.0186\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 295.6046\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 258.4766\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 223.2365\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 191.5345\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 163.4731\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 139.8874\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 121.3198\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 106.9520\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 95.1733\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 85.8920\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 78.1632\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 71.8588\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 66.6445\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 62.0589\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 58.1853\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 54.5365\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 51.4422\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 48.5691\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 46.0589\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 44.0353\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 42.0855\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 40.3820\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 38.9979\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 37.6208\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 1000us/step - loss: 36.4666\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 35.4270\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 34.5505\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 33.7707\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 33.1350\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 1000us/step - loss: 32.6117\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 31.9897\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 31.5319\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 31.1247\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 30.7590\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 30.3785\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 30.0828\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 29.7243\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 29.4802\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 29.2112\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 28.9738\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 28.7288\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 28.5046\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 28.3081\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 999us/step - loss: 28.0883\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 27.8561\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 27.6652\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 27.4925\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 27.2826\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 0s 1000us/step - loss: 27.1026\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 26.9413\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 26.7644\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 26.6826\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 26.4743\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 26.3265\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 26.1957\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 26.0513\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 25.8749\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 25.7501\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 25.7003\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 25.4793\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 25.3506\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 25.2434\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 25.0703\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 24.9519\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 24.8174\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 24.6933\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 24.5828\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 24.4647\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 24.3403\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 24.2318\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 24.1192\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 23.9920\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 23.8760\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 23.7594\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 23.6665\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 23.5383\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 23.4945\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 23.3259\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 23.2188\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 23.1007\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 23.0248\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 22.9016\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.0944\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 1s 1ms/step - loss: 567.9227\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 566.8875\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 565.4016\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 563.1922\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 559.9327\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 554.7880\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 547.4976\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 537.1346\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 523.6777\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 506.2644\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 484.3972\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 458.1146\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 428.3551\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 393.9554\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 357.4351\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 319.4701\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 280.7145\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 243.1145\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 209.0845\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 177.3445\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 151.8707\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 130.0166\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 113.2800\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 99.8500\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 90.0151\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 81.4707\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 74.3779\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 69.2683\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 63.7111\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 58.9926\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 55.1581\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 51.4567\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 48.3105\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 45.5404\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 43.0156\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 40.9140\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 39.0277\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 37.5585\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 36.0016\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 34.8698\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 33.7037\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 32.8084\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 31.9072\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 31.2240\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 30.5690\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 29.9078\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 29.3792\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 28.9458\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 28.4499\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 28.1056\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 27.7147\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 27.4659\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 27.1136\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 26.7858\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 26.5702\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 26.3262\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 999us/step - loss: 26.0901\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 25.8660\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 25.6740\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 25.4423\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 25.2441\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 25.1127\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 0s 1000us/step - loss: 24.9140\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 24.7618\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 24.6003\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 24.4464\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 24.3227\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 24.1558\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 24.0194\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 23.8547\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 23.7233\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 0s 999us/step - loss: 23.5773\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 0s 1000us/step - loss: 23.4443\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 23.3285\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 23.1789\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 23.0644\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 22.9488\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 22.8206\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 22.7327\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 22.6376\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 22.5495\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 22.4065\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 22.2986\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 22.1745\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 22.0745\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 21.9922\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 21.8889\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 21.7800\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 21.6902\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 21.5477\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 21.4286\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 21.3630\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 21.3103\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 21.1945\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 21.0106\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 20.8949\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 20.7918\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 20.6917\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 20.6013\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 20.5262\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 21.9545\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 1s 1ms/step - loss: 588.4791\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 587.7144\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 586.7258\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 585.2334\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 582.7059\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 578.3646\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 571.3661\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 560.7657\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 546.0988\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 526.3334\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 500.7855\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 469.6414\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 434.2188\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 393.6898\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 350.6259\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 306.3685\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 263.4390\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 223.4344\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 186.4099\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 155.3889\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 130.7534\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 111.7348\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 97.3297\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 85.9095\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 77.2285\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 69.9049\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 63.9509\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 58.6284\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 54.0527\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 50.2082\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 46.5569\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 43.5864\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 40.8649\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 38.6625\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 36.6059\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 34.8973\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 33.5153\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.1679\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 31.0393\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 30.0903\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 29.2535\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 28.5301\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 27.9001\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 27.4051\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 26.8899\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 26.4845\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 26.0258\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 25.6921\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 25.3279\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 25.0135\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 24.6779\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 24.4290\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 24.1803\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 23.9154\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 23.7571\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 23.5061\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 23.2976\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 23.0919\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 22.9230\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 22.7463\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 22.5571\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 22.4159\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 22.2842\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 22.0214\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 21.8839\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 21.7211\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 21.5997\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 21.4280\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 21.2878\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 21.1619\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 21.0277\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 20.8775\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 20.7534\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 20.6121\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 20.5083\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 20.4239\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 20.2708\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 20.1615\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 20.0271\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 19.9122\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 19.8167\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 19.6621\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 19.5932\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 19.4559\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 19.2990\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 19.2156\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 19.0921\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 18.9863\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 18.8747\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 18.7866\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 18.6862\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 18.6131\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 18.4978\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 18.3555\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 18.3101\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 18.2011\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 18.1114\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 18.0102\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 17.8897\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 17.8049\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 24.1003\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 1s 1ms/step - loss: 591.8036\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 590.6650\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 589.0035\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 586.4592\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 582.4938\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 576.6249\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 568.1055\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 556.0544\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 539.8586\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 519.1025\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 493.2493\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 462.5536\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 427.3880\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 389.7215\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 348.0072\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 308.1155\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 266.3646\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 228.6545\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 195.2085\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 163.3331\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 138.2449\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 117.3753\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 101.2591\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 88.6589\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 79.0828\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 71.5332\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 65.6544\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 60.8271\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 56.3103\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 52.8042\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 49.5259\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 46.7915\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 44.2159\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 42.1835\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 40.1143\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 38.4314\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 36.8364\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 35.4479\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 34.2048\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 33.2081\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 32.3659\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 31.4979\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 30.8563\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 30.2365\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 29.7463\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 29.2649\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 28.8214\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 28.4314\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 28.0365\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 27.6982\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 27.3711\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 27.0637\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 26.8157\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 26.5585\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 26.3030\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 26.0888\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 25.9000\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 25.5927\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 25.4300\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 25.2713\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 25.0467\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 24.8397\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 24.6118\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 24.4463\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 24.3238\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 24.0661\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 23.9228\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 23.8165\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 23.6658\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 23.5283\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 23.3326\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 23.1655\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 23.0766\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 22.9107\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 22.8020\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 22.6148\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 22.5219\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 22.3832\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 22.2344\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 22.1398\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 21.9704\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 21.8694\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 21.7402\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 21.6417\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 21.5447\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 21.4261\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 21.3300\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 21.2465\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 21.1097\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 21.0094\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 20.8652\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 20.7539\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 20.6349\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 20.5309\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 20.4572\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 20.3157\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 20.2268\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 20.1237\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 19.9988\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 19.9378\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.2097\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 1s 2ms/step - loss: 594.0439\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 593.4176\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 592.7762\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 591.8935\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 590.6181\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 588.5976\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 585.2284\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 579.9915\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 572.2514\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 561.2141\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 545.6039\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 527.2429\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 503.6729\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 475.3867\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 443.6661\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 407.5538\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 369.4290\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 329.0116\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 290.4518\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 252.3280\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 217.6301\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 187.5831\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 162.8951\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 142.6883\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 127.1813\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 114.8548\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 105.9910\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 97.6770\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 91.3716\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 85.5951\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 80.2931\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 75.6441\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 71.2565\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 67.3082\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 63.6240\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 60.3048\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 57.1499\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 54.6208\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 51.8545\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 49.6456\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 47.6795\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 45.6943\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 43.9558\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 42.5083\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 41.1374\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 39.9285\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 38.8201\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 37.8997\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 37.0024\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 36.2835\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 35.5598\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 34.9823\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 34.4468\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 33.8639\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 33.4119\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.9917\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 32.6518\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 32.2743\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 31.9342\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 31.6718\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 31.3745\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 31.0964\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 30.9082\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 30.6263\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 30.4559\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 30.2163\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 29.9438\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 29.7875\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 29.5549\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 29.3890\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 29.1935\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 29.0336\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 28.8558\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 28.7217\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 28.5210\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 28.3648\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 28.2240\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 28.0663\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 27.8891\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 27.7464\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 27.5946\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 27.4418\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 27.3161\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 27.1596\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 27.0307\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 26.8717\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 26.7691\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 26.6096\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 26.4843\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 26.3361\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 26.2250\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 26.1069\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 25.9746\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 25.8591\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 25.7272\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 25.6062\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 25.4944\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 25.3458\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 25.2491\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 25.1430\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.4923\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 1s 2ms/step - loss: 588.9929\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 588.3972\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 587.7350\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 586.9301\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 585.9268\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 584.6180\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 582.8491\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 580.4378\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 577.2844\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 573.0324\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 567.4910\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 560.4183\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 551.8417\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 541.1516\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 528.9457\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 514.8101\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 498.3259\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 479.7272\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 459.7752\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 437.0648\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 413.5236\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 388.5397\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 362.6021\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 336.4347\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 310.4419\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 284.4449\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 259.2290\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 235.8978\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 212.8270\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 192.1094\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 173.3692\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 156.5982\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 141.8208\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 129.0577\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 118.0481\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 108.9342\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 100.9996\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 94.2133\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 88.1192\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 83.1361\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 78.5387\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 74.3866\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 70.6788\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 67.4558\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 64.3929\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 61.4637\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 59.0043\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 56.4637\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 54.2044\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 52.1888\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 50.1791\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 48.4486\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 46.6918\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 45.1633\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 43.7207\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 42.3847\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 41.1544\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 40.0743\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 39.0251\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 38.0547\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 37.1684\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 36.3704\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 35.6203\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 34.9643\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 34.3067\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 33.7371\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2039\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 32.7277\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 32.3075\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 31.8875\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 31.5223\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 31.1560\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 30.7953\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 30.4514\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 30.1625\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 29.8847\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 29.6035\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 29.3846\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 29.1475\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 28.9480\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 28.7276\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 28.5593\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 28.3549\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 28.2174\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 28.0346\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 27.8900\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 27.7343\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 27.5906\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 27.4470\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 27.3175\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 27.1856\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 27.0406\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 26.9393\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 26.7921\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 26.7223\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 26.5464\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 26.4616\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 26.3132\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 26.2486\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 26.1083\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.0528\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 1s 2ms/step - loss: 576.0938\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 575.3865\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 574.5232\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 573.3422\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 571.6370\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 569.0820\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 565.4924\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 560.1447\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 552.7007\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 542.5273\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 529.4230\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 513.2486\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 493.2962\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 469.7956\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 442.5474\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 411.9078\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 379.4237\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 344.2372\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 308.1764\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 273.3208\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 239.7873\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 206.2353\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 176.4335\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 149.1707\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 125.7221\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 105.9759\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 90.7159\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 77.7936\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 68.3063\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 61.1558\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 55.4052\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 50.9710\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 47.3531\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 44.3913\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 41.8767\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 39.7403\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 37.8912\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 36.2919\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 34.7832\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 33.5019\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 32.4806\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 31.4771\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 30.6623\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 29.9177\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 29.2604\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 28.6564\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 28.1057\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 27.6239\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 27.1782\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 26.7286\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 26.4059\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 26.0642\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 25.7446\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 25.5111\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 25.1903\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 24.9654\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 24.7142\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 24.4486\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 24.2792\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 24.0459\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 23.8557\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 23.6949\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 23.5077\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 23.3057\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 23.1770\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 22.9937\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 22.8301\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 22.6882\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 22.5101\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 22.3903\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 22.2239\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 22.0590\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 21.9337\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 21.7755\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 21.6767\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 21.5068\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 21.3836\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 21.2716\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 21.1175\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 21.0016\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 20.8704\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 20.7400\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 20.6521\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 20.4858\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 20.3620\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 20.2587\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 20.1514\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 20.0412\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 19.9195\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 19.8079\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 19.6744\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 19.5795\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 19.4817\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 19.3590\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 19.2443\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 19.1632\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 19.0252\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 18.9034\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 18.8081\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 18.7114\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 47.3829\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 1s 2ms/step - loss: 562.1633\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 561.4001\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 560.3665\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 558.8409\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 556.4684\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 552.7091\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 546.7849\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 537.8904\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 525.5311\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 508.8365\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 486.7587\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 460.8576\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 430.1775\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 394.7271\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 357.1237\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 317.0332\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 277.1602\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 239.0230\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 203.1436\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 172.0530\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 147.0043\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 126.7814\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 112.4715\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 102.3123\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 94.6088\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 88.0610\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 82.4586\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 77.5099\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 72.5423\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 68.5510\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 64.5264\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 60.9495\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 57.6473\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 54.6344\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 51.9920\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 49.4027\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 47.1757\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 45.0962\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 43.3246\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 41.7671\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 40.3611\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 39.1380\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 37.9306\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 36.9343\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 35.9549\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 35.1585\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 34.3731\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 33.7203\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 33.1743\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 32.6054\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.1388\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 31.6875\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 31.3167\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 30.9051\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 30.5705\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 30.2709\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 29.9595\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 29.6685\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 29.4472\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 29.1998\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 28.9905\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 28.7479\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 28.5444\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 28.3736\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 28.1611\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 27.9756\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 27.8060\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 27.5979\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 27.4789\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 27.2460\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 27.0821\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 26.8888\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 26.7434\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 26.5622\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 26.4226\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 26.2765\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 26.1445\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 25.9660\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 25.7932\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 25.6863\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 25.4987\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 25.3764\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 25.1648\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 25.0263\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 24.8832\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 24.7210\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 24.5882\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 24.4381\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 24.3328\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 24.1801\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 24.0403\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 23.9212\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 23.7799\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 23.6661\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 23.5274\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 23.4191\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 23.2960\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 23.1802\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 23.1021\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 22.9675\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 34.9787\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 1s 1ms/step - loss: 596.3789\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 595.6187\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 594.6541\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 593.2715\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 591.0798\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 587.7261\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 582.5427\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 574.6376\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 563.8043\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 549.3306\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 530.6876\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 507.5281\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 479.5345\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 447.2306\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 410.9863\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 371.3977\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 330.5119\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 290.9696\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 251.3272\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 215.6246\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 183.6941\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 156.8015\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 134.1476\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 116.5817\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 103.2621\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 92.2908\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 82.9599\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 75.8318\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 69.8211\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 63.9285\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 59.3048\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 54.8779\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 50.9729\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 47.6277\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 44.5287\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 42.0548\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 39.7807\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 37.7680\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 36.1109\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 34.6977\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 33.3951\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 32.2204\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 31.2556\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 30.3558\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 29.6877\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 28.9942\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 28.4654\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 27.9368\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 27.5001\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 27.1164\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 26.7012\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 26.3347\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 26.1032\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 25.7612\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 25.4926\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 25.2702\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 25.0235\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 24.8315\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 24.6744\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 24.3938\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 24.2128\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 23.9553\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 23.8146\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 23.6375\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 23.4507\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 23.2730\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 23.1082\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 22.9363\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 22.7900\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 22.7015\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 22.4963\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 22.3338\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 22.1980\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 22.0154\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 21.8718\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 21.7291\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 21.6061\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 21.4515\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 21.3102\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 21.1914\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 21.0733\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 20.9031\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 20.7671\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 20.6623\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 20.4996\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 20.3869\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 20.2632\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 20.1194\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 19.9759\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 19.8665\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 19.7529\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 19.6219\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 19.5123\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 19.3779\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 19.3333\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 19.1667\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 19.0815\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 18.9471\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 18.8391\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 18.7025\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 19.1254\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from random import seed\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "estimaters =[]\n",
    "estimaters.append((\"StandardScalerer\",StandardScaler()))\n",
    "estimaters.append((\"mlp\", KerasRegressor(build_fn=larger_model, epochs=100, batch_size=32, verbose=1)))\n",
    "\n",
    "pipeline = Pipeline(estimaters)\n",
    "kfold = KFold(n_splits=10)\n",
    "results = cross_val_score(pipeline, X, y, cv=kfold)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Larger: -24.14 (10.98) MSE\n"
     ]
    }
   ],
   "source": [
    "print(\"Larger: %.2f (%.2f) MSE\" % (results.mean(), results.std()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wider_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_shape=(13,), kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rachit\\AppData\\Local\\Temp\\ipykernel_20620\\2776399509.py:6: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  estimaters.append((\"mlp\", KerasRegressor(build_fn=wider_model, epochs=100, batch_size=5, verbose=0)))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from random import seed\n",
    "from sklearn.model_selection import cross_val_score\n",
    "estimaters = []\n",
    "estimaters.append((\"StandardScaler\", StandardScaler()))\n",
    "estimaters.append((\"mlp\", KerasRegressor(build_fn=wider_model, epochs=100, batch_size=5, verbose=0)))\n",
    "\n",
    "pipeline = Pipeline(estimaters)\n",
    "kfold = KFold(n_splits=10)\n",
    "results = cross_val_score(pipeline, X, y, cv=kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wider : -12.99 (6.62)\n"
     ]
    }
   ],
   "source": [
    "print(\"Wider : %.2f (%.2f)\" % (np.mean(results), np.std(results)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "def wider_deep_model():\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(25, input_dim=13, kernel_initializer=\"normal\" , activation='relu'))\n",
    "    model.add(Dense(18, kernel_initializer=\"normal\" , activation='relu'))\n",
    "    model.add(Dense(7, kernel_initializer=\"normal\" , activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer=\"normal\" ))\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return  model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rachit\\AppData\\Local\\Temp\\ipykernel_20620\\852207824.py:10: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  estimaters.append((\"mlp\", KerasRegressor(build_fn=wider_deep_model, nb_epoch=100, batch_size=5, verbose=0)))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "from random import seed\n",
    "from sklearn.model_selection import cross_val_score\n",
    "estimaters = []\n",
    "estimaters.append((\"StandardScaler\", StandardScaler()))\n",
    "estimaters.append((\"mlp\", KerasRegressor(build_fn=wider_deep_model, nb_epoch=100, batch_size=5, verbose=0)))\n",
    "\n",
    "pipeline = Pipeline(estimaters)\n",
    "kfold = KFold(n_splits=10)\n",
    "results = cross_val_score(pipeline, X, y, cv=kfold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deeper and Wider : -564.99 (105.56)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(\"Deeper and Wider : %.2f (%.2f)\" % (np.mean(results), np.std(results)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
